# CVPR2023

https://github.com/amusi/CVPR2023-Papers-with-Code



# [Avatars](https://github.com/amusi/CVPR2023-Papers-with-Code#avatars)

**Structured 3D Features for Reconstructing Relightable and Animatable Avatars**

- Homepage: https://enriccorona.github.io/s3f/
- Paper: https://arxiv.org/abs/2212.06820
- Code: None
- Demo: https://www.youtube.com/watch?v=mcZGcQ6L-2s

本文提出结构化3D特征，一种基于新的隐性3D表示的模型，将像素对齐的图像特征汇集到从参数化、统计的人体网格表面采样的密集3D点上。三维点具有关联的语义，可以在三维空间中自由移动。这允许最佳覆盖的人的兴趣，除了身体形状，反过来，这有助于建模配件，头发和宽松的衣服。本文提出一个完整的基于3D transformer的注意力框架，给定一个人在无约束姿态下的单一图像，生成一个具有反照率和光照分解的可动画3D重建，是一个单一的端到端模型的结果，半监督训练，没有额外的后处理。

S3F模型在各种任务上超过了之前的最先进技术，包括单目3D重建，以及反照率和阴影估计。所提出方法允许新视图合成、重光照和重新摆位重建，并可以自然地扩展到处理多个输入图像(例如，一个人的不同视图，或视频中不同姿态的同一视图)。最后，展示了该模型在3D虚拟试衣应用中的编辑能力。



**Learning Personalized High Quality Volumetric Head Avatars from Monocular RGB Videos**

- Homepage: https://augmentedperception.github.io/monoavatar/
- Paper: https://arxiv.org/abs/2304.01436

本文提出一种方法，从野外捕获的单目RGB视频中学习高质量的隐式3D头部化身。学习的头像由一个参数化的人脸模型驱动，以实现用户控制的面部表情和头部姿势。所提出的混合管道将3DMM的几何先验和动态跟踪与神经辐射场相结合，以实现细粒度控制和照片真实感。为减少过平滑和改进模型外表达式合成，本文建议预测锚定在3DMM几何上的局部特征。这些学习到的特征由3DMM变形驱动，并在3D空间中插值，以产生指定查询点的体辐射度。进一步表明，在UV空间中使用卷积神经网络对合并空间上下文和产生有代表性的局部特征至关重要。广泛的实验表明，能够重建高质量的化身，具有更准确的依赖于表情的细节，对训练外表情的良好泛化，并在数量上优于其他最先进的方法。



# [视觉和语言(Vision-Language)](https://github.com/amusi/CVPR2023-Papers-with-Code#视觉和语言vision-language)

**CapDet: Unifying Dense Captioning and Open-World Detection Pretraining**

- Paper: https://arxiv.org/abs/2303.02489
- Code: None

CapDet：统一密集字幕和开放世界检测预训练

[龙彦新](https://arxiv.org/search/cs?searchtype=author&query=Long,+Y)、[文友鹏](https://arxiv.org/search/cs?searchtype=author&query=Wen,+Y)、[韩建华](https://arxiv.org/search/cs?searchtype=author&query=Han,+J)、[徐航](https://arxiv.org/search/cs?searchtype=author&query=Xu,+H)、[任鹏珍](https://arxiv.org/search/cs?searchtype=author&query=Ren,+P)、[张伟](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+W)、[赵申](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+S)、[梁晓丹](https://arxiv.org/search/cs?searchtype=author&query=Liang,+X)

> 受益于对图像-文本对的大规模视觉语言预训练，开放世界检测方法在零样本或少样本检测设置下表现出了优异的泛化能力。然而，现有方法的推理阶段仍然需要预定义的类别空间，并且仅预测属于该空间的对象。为了引入“真正的”开放世界检测器，在本文中，我们提出了一种名为 CapDet 的新颖方法，可以在给定类别列表下进行预测或直接生成预测边界框的类别。具体来说，我们通过引入额外的密集字幕头来生成基于区域的字幕，将开放世界检测和密集字幕任务统一到一个单一但有效的框架中。此外，添加字幕任务将有利于检测性能的泛化，因为字幕数据集涵盖了更多概念。实验结果表明，通过统一密集字幕任务，我们的 CapDet 比 LVIS（1203 类）上的基线方法获得了显着的性能改进（例如，LVIS 稀有类上的 mAP +2.1%）。此外，我们的 CapDet 还在密集字幕任务上实现了最先进的性能，例如，VG V1.2 上的 mAP 为 15.44%，VG-COCO 数据集上的 mAP 为 13.98%。



# [三维重建(3D Reconstruction)](https://github.com/amusi/CVPR2023-Papers-with-Code#三维重建3d-reconstruction)

**Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition**

- Homepage: https://moygcc.github.io/vid2avatar/
- Paper: https://arxiv.org/abs/2302.11566
- Code: https://github.com/MoyGcc/vid2avatar
- Demo: https://youtu.be/EGi47YeIeGQ

![image-20231026110155867](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026110155867.png)

**适合还是不适合：基于模型的人脸重建和弱监督遮挡分割**

- 论文：[https ://arxiv.org/abs/2106.09614](https://arxiv.org/abs/2106.09614)
- 代码： https: [//github.com/unibas-gravis/Occlusion-Robust-MoFA](https://github.com/unibas-gravis/Occlusion-Robust-MoFA)



**单幅图像的 3D 电影摄影**

- 主页： https: [//xingyi-li.github.io/3d-cinemagraphy/](https://xingyi-li.github.io/3d-cinemagraphy/)
- 论文：[https ://arxiv.org/abs/2303.05724](https://arxiv.org/abs/2303.05724)
- 代码： https: [//github.com/xingyi-li/3d-cinemagraphy](https://github.com/xingyi-li/3d-cinemagraphy)

生成动图 没啥相关 但是挺有意思的

![image-20231026110516284](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026110516284.png)

**FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction**

- Paper: https://arxiv.org/abs/2211.13874
- Code: https://github.com/csbhr/FFHQ-UV

构造数据集，从标准化的面部图像中生成高质量的 UV 贴图。



**A Hierarchical Representation Network for Accurate and Detailed Face Reconstruction from In-The-Wild Images**

- Homepage: https://younglbw.github.io/HRN-homepage/

- Paper: https://arxiv.org/abs/2302.14434

- Code: https://github.com/youngLBW/HRN

  **用于从野外图像中准确、详细地重建人脸的分层表示网络**

![image-20231026111502428](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026111502428.png)

# [3D人体Mesh估计(3D Human Mesh Estimation)](https://github.com/amusi/CVPR2023-Papers-with-Code#3d人体mesh估计3d-human-mesh-estimation)

**3D Human Mesh Estimation from Virtual Markers**

基于虚拟标记的三维人体网格估计
(CVPR 2023)

- Paper: https://arxiv.org/abs/2303.11726
- Code: https://github.com/ShirleyMaxx/VirtualMarker

![image-20231026102822504](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026102822504.png)







其他



**HOOD: Hierarchical Graphs for Generalized Modelling of Clothing Dynamics**

HOOD：服装动力学广义建模的层次图

- Homepage: https://dolorousrtur.github.io/hood/
- Paper: https://arxiv.org/abs/2212.07242
- Code: https://github.com/dolorousrtur/hood
- Demo: https://www.youtube.com/watch?v=cBttMDPrUYY



**SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation**

**SadTalker：学习逼真的 3D 运动系数，用于风格化音频驱动的单图像说话人脸动画**

- 论文：[https ://arxiv.org/abs/2211.12194](https://arxiv.org/abs/2211.12194)
- 代码： https: [//github.com/Winfredy/SadTalker](https://github.com/Winfredy/SadTalker)
- 可能只有视频 没建模 

![image-20231026112544141](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026112544141.png)

**GFPose: Learning 3D Human Pose Prior with Gradient Fields**

**GFPose：使用梯度场先学习 3D 人体姿势**

- 论文：https://arxiv.org/abs/2212.08641
- 代码： https: [//github.com/Embracing/GFPose](https://github.com/Embracing/GFPose)

![image-20231026112725224](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20231026112725224.png)

、https://cfcs.pku.edu.cn/news/241376.htm



This study presents a novel approach, combining Graph Neural Networks (GNNs) with a Multi-Hypothesis Transformer, to enhance the accuracy of 3D human pose estimation in monocular videos. Existing methods have limitations in modeling relationships between hypotheses and facilitating cross-hypothesis communication. To address these issues, we introduce GNNs to model global dependencies among hypotheses, leveraging the strengths of the Multi-Hypothesis Transformer for comprehensive processing. Specifically, we utilize the initial hypothesis representations as input nodes in a graph and employ GNNs to learn relationships among nodes, effectively propagating and aggregating feature information. Subsequently, through a staged process of self-hypothesis communication and cross-hypothesis communication, we generate the final 3D pose estimation. Extensive experiments on challenging datasets, including Human3.6M and MPI-INF-3DHP, demonstrate the significant superiority of our method. Compared to previous approaches, our proposed framework achieves remarkable improvements in accuracy, showcasing the potential and advantages of integrating GNNs with the Multi-Hypothesis Transformer for 3D human pose estimation.

## B站



【HumanTOMATO：文本对齐的全身人体动作生成】 https://www.bilibili.com/video/BV1xH4y1973x/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【[CVPR2023] NeAT论文讲解 | 从图片重建三维开曲面 | 腾讯AIGC | 已开源】 https://www.bilibili.com/video/BV1bP411R7Ry/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【DrapeNet：服装生成和自监督立体裁剪 [CVPR 2023] 【双语字幕】】 https://www.bilibili.com/video/BV13P411e79S/?share_source=copy_web

【ICCV 2023: 单图生成逼真的三维人体角色【三星】】 https://www.bilibili.com/video/BV1ow411X7yZ/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【ICCV 2023 MotionBERT: 人体运动表征统一预训练  [北大|商汤|上海AI Lab] 【双语字幕】】 https://www.bilibili.com/video/BV1s8411S7ZM/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【ICCV 2023 MotionBERT: 人体运动表征统一预训练  [北大|商汤|上海AI Lab] 【双语字幕】】 https://www.bilibili.com/video/BV1s8411S7ZM/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【CVPR 2023|音频驱动共语手势生成】 https://www.bilibili.com/video/BV1ks4y1R7E9/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【CVPR 2023|数字虚拟人生成】 https://www.bilibili.com/video/BV1wX4y1C7QE/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e

【CVPR 2023|基于动漫人物画像的风格化单视图3D重建】 https://www.bilibili.com/video/BV1do4y187sP/?share_source=copy_web&vd_source=067de257d5f13e60e5b36da1a0ec151e