# 姿态估计 姿态识别 深度学习课程 驱动

博客：

23

https://zhuanlan.zhihu.com/p/400922771



22

人体姿态估计综述

https://zhuanlan.zhihu.com/p/456240275



21

https://www.cnblogs.com/wxkang/p/15087239.html



21

[三维人体姿态估计年度进展综述（周晓巍教授）_人体姿态识别取得进展_Highlight_Jin的博客-CSDN博客](https://blog.csdn.net/Highlight_Jin/article/details/114761071)

综述论文：

23

http://fcst.ceaj.org/CN/abstract/abstract3211.shtml



[【万字长文！人体姿态估计(HPE)入门教程】 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/596043913)

[3D人体姿态估计论文汇总（CVPR/ECCV/ACCV/AAAI）-CSDN博客](https://yongqi.blog.csdn.net/article/details/107625327)

3D人体姿态估计是从图片或视频中估计出关节点的三维坐标 (x, y, z)，它本质上是一个回归问题。

它广泛地应用在动画、游戏、运动捕捉系统和行为理解中，也可以做为其他算法的辅助环节（行人重识别），并可以跟人体相关的其他任务一起联合学习（人体解析）。

### **挑战**

然而，因为一个2D骨架可以对应多个3D骨架，它具有在单视角下2D到3D映射中固有的深度模糊性与不适定性，这也导致了它本身就具有挑战性。

目前，3D姿态估计的主要瓶颈是缺少大型的室外数据集，并缺少一些特殊姿态的数据集（如摔倒, 打滚等）。这主要由于3D姿态数据集是依靠适合室内环境的动作捕捉（MOCAP）系统构建的，而MOCAP系统需要带有多个传感器和紧身衣裤的复杂装置，在室外环境使用是不切实际的。因此数据集大多是在实验室环境下建立的，模型的泛化能力也比较差。

## 论文

cvpr 2022



## MHFormer



https://zhuanlan.zhihu.com/p/502920839



 #### Related works

三维人体姿态估计旨在利用计算机视觉技术，从图片或视频中估计出人体关键点在三维空间中的坐标。它可广泛用于虚拟现实、元宇宙、体育比赛中（冬奥运实时动捕、滑雪）。该任务通常被解耦成2个子任务：二维姿态估计和二维到三维姿态提升（2D-to-3D Pose Lifting）。尽管该方法目前已经取得了不错的性能，但是它还面临着许多挑战，例如二维到三维映射的深度模糊性与人体的自遮挡问题。



​	Estimating 3D human poses from monocular videos is a challenging task due to depth ambiguity and self-occlusion. Most existing works attempt to solve both issues by exploiting spatial and temporal relationships. However, those works ignore the fact that it is an inverse problem where multiple feasible solutions (i.e., hypotheses) exist. To relieve this limitation, we propose a Multi-Hypothesis Transformer (MHFormer) that learns spatio-temporal representations of multiple plausible pose hypotheses. In order to effectively model multi-hypothesis dependencies and build strong relationships across hypothesis features, the task is decomposed into three stages: (i) Generate multiple initial hypothesis representations; (ii) Model self-hypothesis communication, merge multiple hypotheses into a single converged representation and then partition it into several diverged hypotheses; (iii) Learn cross-hypothesis communication and aggregate the multi-hypothesis features to synthesize the final 3D pose. Through the above processes, the final representation is enhanced and the synthesized pose is much more accurate. Extensive experiments show that MHFormer achieves stateof-the-art results on two challenging datasets: Human3.6M and MPI-INF-3DHP. Without bells and whistles, its performance surpasses the previous best result by a large margin of 3% on Human3.6M. Code and models are available at https://github.com/Vegetebird/MHFormer.







### **研究动机**

![img](https://pic2.zhimg.com/80/v2-60705386bfcdd129b20bb464290a1309_720w.webp)

先前的工作尝试使用时空图卷积或时空Transformer来利用时空约束来解决该问题。然而，该任务也是一个存在多个可行解（假设）的逆问题（inverse problem），具有巨大的歧义性。该问题的产生主要是由于相机成像过程中深度信息的丢失，造成多个三维姿态投影到二维空间可能存在相同的二维姿态。从而形成一对多的病态问题，并且在遮挡的情况下该问题会被进一步放大。这些工作大多忽略了该问题本质上是个逆问题，并且只假设存在一个解，这通常会导致估计出不满意的结果（见图1）。

目前，只有少量的工作提出基于生成多个假设的方法。他们通常依赖于一对多的映射，将多个输出头添加到具有共享特征提取器的现有架构中，而未能建立不同假设特征之间的联系。这是一个重要的缺点，因为这种能力对于提高模型的表现力和性能至关重要。 鉴于三维人体姿态估计的歧义逆问题，本文认为先进行一对多的映射，然后再将生成的多个中间假设进行多对一的映射更为合理，因为这种方式可以丰富模型的特征并可以合成更精确的三维姿态。

### **模型方法**

![img](https://pic1.zhimg.com/80/v2-babebc345587987f235fc49f40ebac78_720w.webp)

这篇文章的核心思想是通过学习多重姿态假设的时空表示来合成更准确的三维姿态。 为了实现这一点，作者提出了一个三阶段框架，叫多假设Transformer（Multi-Hypothesis Transformer，MHFormer）。如图2所示，该框架从生成多个初始表示开始，逐渐在它们之间进行通信以合成更准确的估计。该框架可以有效地建模多假设的依赖，并在假设特征之间建立牢固的联系。

以下这张图是本文的具体网络结构。这张图很大，但还是挺好理解的。左上角的图a是MHFormer的整体框架。输入是二维姿态序列，输出是中间帧的三维姿态。MHFormer总共包括三个主要模块：多假设生成器（右上角图b），自假设修正器（左下角图c），交叉假设交互器（右下角图d）和2个辅助模块：时间嵌入，回归头。

![img](https://pic4.zhimg.com/80/v2-57dfff4ce9eb3e732f1d0c04084a661b_720w.webp)

#### **多假设生成**

在空间域中，作者通过设计一个基于Transformer的级联架构来建模每帧人体关键点的内在结构信息，并在网络的不同层生成姿态假设的不同表示。该模块命名为多假设生成器（Multi-Hypothesis Generation，MHG），公式如下：

�0�=LN(��)+��������′�=��−1�+MSA�⁡(LN(��−1�),��′′�=��′�+MLP�(LN(��′�),��1�=��+LN(��1′′�)

#### **时间嵌入**

MHG在空域将多级特征视作姿态假设的初始表示，然而他们的特征表达能力是比较有限的。考虑到这点，本文接下来对这些特征在时域进行捕获依赖性并建立特征之间的联系以进行信息增强。

那么要想利用时序信息，首先应将特征从空域转化到时域。因此，本文首先用了一个矩阵转置操作，来交换矩阵的维度，并对特征进行编码同时引入帧的位置信息。





## PoseFormer

https://blog.csdn.net/gaoqing_dream163/article/details/132121074

- **PoseFormer**，**一种纯粹基于Transformer的方法，用于视频中的3D人体姿势估计，不涉及卷积架构**。

- **PoseFormer使用两个维度的不同Transformer模块直接对空间和时间方面进行建模**。





**基于2D->3D**

## 《3D Human Pose Estimation = 2D Pose Estimation + Matching》



- **《3D Human Pose Estimation = 2D Pose Estimation + Matching》**

总结：首先是做2D的人体姿态估计，然后基于Nearest neighbor最近邻的match来从training data中找最像的姿态。2D的姿态估计算法是基于**CPM**来做的。3D的match方法是[KNN](https://link.zhihu.com/?target=https%3A//blog.csdn.net/u010608296/article/details/120640343)方法，先把training data中的人体3d骨架投射到2D空间，然后把test sample的2d骨架跟这些training data进行对比，最后使用最相近的2d骨架对应的3D骨架当成最后test sample点3D骨架。当training数据量非常多的时候，这种方法可能可以保证比较好的精度，但是在大部分时候，这种匹配方法的精度较粗，而且误差很大。

![img](https://pic2.zhimg.com/80/v2-c61fdf8442e812053140f25657ff4afd_720w.webp)

图 思路框架图



## SimpleBasline-3D

- [SimpleBasline-3D](https://link.zhihu.com/?target=https%3A//github.com/weigq/3d_pose_baseline_pytorch)：**《A Simple Yet Effective Baseline for 3d Human Pose Estimation》**

论文动机：论文作者开头就提到，目前最先进的 3d 人体姿态估计方法主要集中在端到端（直接回归）的方法，即在给定原始图像像素的情况下预测 3d 关节位置。尽管性能优异，但通常很难理解它们的误差来源于 2d姿态估计部分过程(visual)，还是将 2d 姿势映射到 3d关节的过程。因此，作者**将 3d 姿态估计解耦为2d 姿态估计和从2d 到 3d 姿态估计（即，**3**D姿态估计 = 2D姿态估计 + (2D->3D)），重点关注** **(2D->3D)。**所以作者提出了一个从2D关节到3D关节的系统，**系统的输入是 2d 个关节位置数组，输出是 3d 中的一系列关节位置，**并将其误差降到很低，从而证明3D姿态估计的误差主要来源于图像到2D姿态的过程，即视觉理解(visual)的过程。

![img](https://pic4.zhimg.com/80/v2-7611347f534205ebb4a78191b4e6004f_720w.webp)

图 SimpleBasline-3D网络结构

同样，从这个工作的名字可以看出，这个工作提出了一个比较simple的baseline，但是效果还是非常明显。方法上面来讲，就是先做一个2d skeleton的姿态估计，方法是基于**Hourglass**的，文章中的解释是较好的效果以及不错的速度。 基于获得的2d骨架位置后，后续接入两个fully connected的操作，直接回归3D坐标点。这个做法非常粗暴直接，但是效果还是非常明显的。在回归之前，需要对坐标系统做一些操作。





**基于时序（视频序列）**：

## VideoPose3D



- **VideoPose3D**：《3D human pose estimation in video with temporal convolutions and semi-supervised training》
  利用这篇是利用视频做姿态估计的比较经典的论文，使用了多帧的图像来估计姿态，直觉上应该比单帧姿态估计要更加准确。两个贡献：
  1. 提出了一种基于2D关节点轨迹的空洞时域卷积方法，简单、有效的预测出视频中的3D人体姿态；
  2. 引入了一种半监督的方法，它利用了未标记的视频，并且在标记数据稀缺的情况下是有效的。

![img](https://pic4.zhimg.com/80/v2-11410e6c5bba030146780d9096be108f_720w.webp)

图 temporal convolutional model

![img](https://pic1.zhimg.com/80/v2-0f450778f1dfd51c856b2e8239e78978_720w.webp)

图 An instantiation of our fully-convolutional 3D pose estimation architecture.



## MotionBERT

应该是目前最好的

[Walter0807/MotionBERT: [ICCV 2023\] PyTorch Implementation of "MotionBERT: A Unified Perspective on Learning Human Motion Representations" (github.com)](https://github.com/Walter0807/MotionBERT)

[【论文笔记】Unified Human-Centric Model 系列之MotionBERT - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/645577331)

[MotionBert论文解读及详细复现教程-CSDN博客](https://blog.csdn.net/m0_56661101/article/details/131780054)

https://aitechtogether.com/python/137509.html



可以点开↓

[MotionBERT.md](./MotionBERT.md)




## 相关总结

**3D单人单视图HPE方法**：

1. **直接估计方法**:2D视频 -> 3D Pose



2. **2D-to-3D lifting 方法**: 2D视频 -> 2D Pose -> 3D Pose

直接估计方法从2D图像或视频帧中推断出3D人体姿势，而无需中间估计2D姿势表示。

- 2D姿态检测器：OpenPose、CPN、AlphaPose和HRNet被广泛用作2D姿态检测器。

- GNNs

  人体姿势可以表示为一个graph，其中关节是nodes ，骨骼是 edges

  对于PoseFormer：

  transformer可以被视为一种具有独特且通常有利的图操作的GNN。

  节点之间连接的强度由transformer的self-attention机制决定，而不是像典型的那样通过邻接矩阵预定义。

- SimpleBaseline 

  proposes a fully-connected residual network to lift 2D keypoints to 3D joint locations from a single frame.提出了一种全连接残差网络，将2D关键点从单帧提升到3D关节位置。



**vit** Vision Transformers
	DEtection TRansformer (DETR) 用于目标检测与全景分割。
	Vision Transformer (ViT) ，纯Transformer 构架，在图像分类方面达到了SOAT的性能。
	Transpose，基于Transformer 构架，从图像中估计3D姿态。
	MEsh TRansfOrmer，将cnn与Transformer 网络结合起来，从单个图像重建3D pose 和 mesh vertices。

- PoseFormer （[PoseFormer](# PoseFormer)）

  本文方法的时空Transformer 架构利用了每帧中的关键点相关性，并保留了视频中的自然时间一致性。

-  Strided Transformer [21]

   introduce a Transformer-based architecture with strided convolutions to lift a long 2D pose sequence to a single 3D pose.



MHFormer（[MHFormer](# MHFormer)）

​		

### 4.3 最新进展

关于最新进展，大家同样可以在**paperswithcode**网站去关注数据集**Human3.6**的榜单。

下面这个榜单是**没使用**2DGT数据集的：

[/monocular-3d-human-pose-estimationpaperswithcode.com/task/monocular-3d-human-pose-estimation](https://link.zhihu.com/?target=https%3A//paperswithcode.com/task/monocular-3d-human-pose-estimation)

下面这个榜单是**使用**2DGT数据集：

[Human3.6M Benchmark (3D Human Pose Estimation)paperswithcode.com/sota/3d-human-pose-estimation-on-human36m![img](https://pic4.zhimg.com/v2-26aeab0bc331b6f555dbdab836f4684b_180x120.jpg)](https://link.zhihu.com/?target=https%3A//paperswithcode.com/sota/3d-human-pose-estimation-on-human36m)



## 作业相关

#### 动机

(如人机交互，运动分析，医疗保健)。

虚拟现实、元宇宙、体育比赛中（冬奥运实时动捕、滑雪）。

6.2 行为识别

自动驾驶的感知领域，行人行为识别、手势识别等是可以看得见的应用。但是，目前的自动驾驶好像并没有做到这一块，因为目前的自动驾驶还在“躲避障碍物”的阶段，检测任务还是应用的主流，行人的行为识别还存在比较远的路，精度、速度都是限制。

6.3 虚拟驱动

数字人、数字驱动、游戏建模，AR，VR，游戏和动画是目前的应用主流，这种限制场景下的姿态有实现的硬件基础；但是，单目的姿态估计感觉还是没有多视角的应用多，因为多一个摄像头不会花很多钱，还能提高精度；但是少一个摄像头的精度下降可能会带来体验感的下降。

